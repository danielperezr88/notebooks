{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA SET CANCER DE MAMA https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECORDATORIO ayuda de panda recordset\n",
    "df = pd.read_csv('sp500_ohlc.csv', index_col = 'Date', parse_dates=True)\n",
    "print df.head()\n",
    "df2 = df['Open']\n",
    "print df2.head()\n",
    "df3 = df[['Close','High']]\n",
    "print df3.head()\n",
    "df3.rename(columns={'Close': 'CLOSE!!'}, inplace=True)\n",
    "print df3.head()\n",
    "df4 = df3[(df3['CLOSE!!'] > 1400)]\n",
    "print df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### panda recordatorio OPERACIONES DE COLUMNAS\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "df = pd.read_csv('sp500_ohlc.csv', index_col = 'Date', parse_dates=True)\n",
    "#notice what i did, since it is an object\n",
    "df['H-L'] = df.High - df.Low\n",
    "\n",
    "print df.head()\n",
    "df['100MA'] = pd.rolling_mean(df['Close'], 100)\n",
    "\n",
    "#### must do a slice, since there will be no value for 100ma until 100 points\n",
    "print df[200:210]\n",
    "\n",
    "df['Difference'] = df['Close'].diff()\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mas sobre ILOC\n",
    "df = pd.DataFrame({'A':['a', 'b', 'c'], 'B':[54, 67, 89]}, index=[100, 200, 300])\n",
    "\n",
    "df\n",
    "\n",
    "                        A   B\n",
    "                100     a   54\n",
    "                200     b   67\n",
    "                300     c   89\n",
    "In [19]:    \n",
    "df.loc[100]\n",
    "\n",
    "Out[19]:\n",
    "A     a\n",
    "B    54\n",
    "Name: 100, dtype: object\n",
    "\n",
    "In [20]:    \n",
    "df.iloc[0]\n",
    "\n",
    "Out[20]:\n",
    "A     a\n",
    "B    54\n",
    "Name: 100, dtype: object\n",
    "\n",
    "In [24]:    \n",
    "df2 = df.set_index([df.index,'A'])\n",
    "df2\n",
    "\n",
    "Out[24]:\n",
    "        B\n",
    "    A   \n",
    "100 a   54\n",
    "200 b   67\n",
    "300 c   89\n",
    "\n",
    "In [25]:    \n",
    "df2.ix[100, 'a']\n",
    "\n",
    "Out[25]:    \n",
    "B    54\n",
    "Name: (100, a), dtype: int64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aunque esta para python 3.4 originalmente lo estoy ejecutando en 2.7 de forma que documentare las funciones que sean incompatibles\n",
    "\n",
    "#### atencion, para aprendizaje, creo un archivo txt de origenes de datos llamado breast-cancer-wisconsin.data.txt que no es el original (breast-cancer-wisconsin.data-TOTAL.txt), sino una copia con TRES CAMPOS + 1 LABEL . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from sklearn import preprocessing, cross_validation, neighbors\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data_total.txt')\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(['id'], 1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Unifom_Cell_Size</th>\n",
       "      <th>Uniform_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clump_Thickness  Unifom_Cell_Size  Uniform_Cell_Shape  Marginal_Adhesion  \\\n",
       "0                5                 1                   1                  1   \n",
       "1                5                 4                   4                  5   \n",
       "2                3                 1                   1                  1   \n",
       "3                6                 8                   8                  1   \n",
       "4                4                 1                   1                  3   \n",
       "\n",
       "   Single_Epithelial_Cell_Size Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli  \\\n",
       "0                            2           1                3                1   \n",
       "1                            7          10                3                2   \n",
       "2                            2           2                3                1   \n",
       "3                            3           4                3                7   \n",
       "4                            2           1                3                1   \n",
       "\n",
       "   Mitoses  Class  \n",
       "0        1      2  \n",
       "1        1      2  \n",
       "2        1      2  \n",
       "3        1      2  \n",
       "4        1      2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clump_Thickness                3\n",
       "Unifom_Cell_Size               1\n",
       "Uniform_Cell_Shape             1\n",
       "Marginal_Adhesion              1\n",
       "Single_Epithelial_Cell_Size    2\n",
       "Bare_Nuclei                    2\n",
       "Bland_Chromatin                3\n",
       "Normal_Nucleoli                1\n",
       "Mitoses                        1\n",
       "Class                          2\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# condiciones \n",
    "df[df.Class > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CLASIFICADOR montamos los arrays de NUMPY\n",
    "\n",
    "X = np.array(df.drop(['Class'], 1))\n",
    "y = np.array(df['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978571428571\n"
     ]
    }
   ],
   "source": [
    "# a partir de x e y, planteamiento original de clasificador svm \n",
    "\n",
    "from sklearn import preprocessing, cross_validation, neighbors, svm\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# utilizamos el support vector classifier  \n",
    "clf = svm.SVC()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "confidence = clf.score(X_test, y_test)\n",
    "print(confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARIOS CLASIFICADORES CON CROSSFOLDER MEDIANTE LA FUNCION SIGUIENTE:  run_cv(X,y,clf_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -------------------------  VARIOS CLASIFICADORES ----------------------------\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "#  definimos la funcion de cross validation\n",
    "def run_cv(X,y,clf_class,**kwargs):\n",
    "    # Construimos el objeto kfolds \n",
    "    kf = KFold(len(y),n_folds=5,shuffle=True)\n",
    "    y_pred = y.copy()\n",
    "    \n",
    "    # tenemos  que iterar sobre todos los kfolds\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        \n",
    "        \n",
    "        # Iniciamos el clasificador con los keywords arguments...\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------  Confianzas de los calsificadores: \n",
      "Confianza de SVC =  0.971428571429\n",
      "MATRIZ DE CONFUSION de SVC \n",
      "[[431  27]\n",
      " [  3 238]] \n",
      "\n",
      "Confianza de KNN =  0.978571428571\n",
      "MATRIZ DE CONFUSION de KNN \n",
      "[[448  10]\n",
      " [ 10 231]] \n",
      "\n",
      "Confianza de  Log. Regression =  0.842857142857\n",
      "MATRIZ DE CONFUSION de Log. Regression \n",
      "[[445  13]\n",
      " [ 15 226]] \n",
      "\n",
      "Confianza de Random forest: 0.957142857143\n",
      "MATRIZ DE CONFUSION de RANDOM FOREST \n",
      "[[444  14]\n",
      " [ 17 224]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn import preprocessing, cross_validation, neighbors, svm\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# AÑADIMOS  varios clasificadores al SVC Original \n",
    "from sklearn.svm import SVC\n",
    "# estos nuevos\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.linear_model import LogisticRegression as LOG_REG\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# utilizamos el support vector classifier  \n",
    "clf = svm.SVC()\n",
    "clf2 = neighbors.KNeighborsClassifier()\n",
    "clf3 = LogisticRegression(C=0.001, penalty='l2')\n",
    "\n",
    "\n",
    "#clf3 = ensemble.RandomForestClassifier()\n",
    "#clf_RF = ensemble.RandomForestClassifier()   esto da error\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf2.fit(X_train, y_train)\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "# RF.fit(X_train, y_train)  me da error al aplicar la funcion así\n",
    "\n",
    "# ----- Lista de Predictiones -----------------\n",
    "predictions = clf.predict(X_test)\n",
    "predictions2 = clf2.predict(X_test)\n",
    "predictions3 = clf3.predict(X_test)\n",
    "\n",
    "\n",
    "# ------- Printing ---------------\n",
    "print \"--------  Confianzas de los calsificadores: \"\n",
    "confidence_SVC = clf.score(X_test, y_test)\n",
    "print \"Confianza de SVC = \", confidence_SVC\n",
    "print \"MATRIZ DE CONFUSION de SVC \\n\", confusion_matrix(y,run_cv(X,y,SVC)), \"\\n\"\n",
    "\n",
    "confidence_KNN = clf2.score(X_test, y_test)\n",
    "print \"Confianza de KNN = \", confidence_KNN\n",
    "print \"MATRIZ DE CONFUSION de KNN \\n\", confusion_matrix(y,run_cv(X,y,KNN)), \"\\n\"\n",
    "\n",
    "confidence_LOG_REG = clf3.score(X_test, y_test)\n",
    "print \"Confianza de  Log. Regression = \", confidence_LOG_REG\n",
    "print \"MATRIZ DE CONFUSION de Log. Regression \\n\", confusion_matrix(y,run_cv(X,y,LOG_REG)), \"\\n\"\n",
    "\n",
    "# CON RANDOM FOREST, usamos la funcion anterior de croos folder\n",
    "def accurade(y_true,y_pred):\n",
    "    # NumPy interprets True and False as 1. and 0.\n",
    "    return np.mean(y_true == y_pred)\n",
    "#print \"%.3f\" % accuracy(y, run_cv(X,y,RF))\n",
    "print \"Confianza de Random forest:\", accuracy(y_test, run_cv(X_test,y_test,RF))\n",
    "#print \"Random forest:\", accuracy(y, run_cv(X,y,RF))\n",
    "print \"MATRIZ DE CONFUSION de RANDOM FOREST \\n\", confusion_matrix(y,run_cv(X,y,RF)), \"\\n\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### NOTA En lo ultimo tambien prodiamos usar tal como hicimos en el del churn.. \n",
    "print \"Support vector machines:\"\n",
    "print \"%.3f\" % accuracy(y, run_cv(X,y,SVC))\n",
    "print \"Random forest:\"\n",
    "print \"%.3f\" % accuracy(y, run_cv(X,y,RF))\n",
    "print \"K-nearest-neighbors:\"\n",
    "print \"%.3f\" % accuracy(y, run_cv(X,y,KNN))\n",
    "\n",
    "\n",
    "####  ---       predicciones que no seé porque no funciona (???) -------------------------------\n",
    "print \"Predicciones para el SVM ----\"\n",
    "print 'Precision: ', precision_score(y_test, predictions)\n",
    "print 'Recall: ', recall_score(y_test, predictions)\n",
    "print 'Accuracy: ', accuracy_score(y_test, predictions)\n",
    "\n",
    "print \" Predicciones para el KNN ----\"\n",
    "print 'Precision: ', precision_score(y_test, predictions2)\n",
    "print 'Recall: ', recall_score(y_test, predictions2)\n",
    "print 'Accuracy: ', accuracy_score(y_test, predictions2)\n",
    "\n",
    "###  etc...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculamos los limites de los SLIDES de BOKEH para que estén derentro del margen de los valores del data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, -99999, 1, 1, 1, 2]\n",
      "[10, 10, 10, 10, 10, '9', 10, 10, 10, 4]\n"
     ]
    }
   ],
   "source": [
    "# RECORREMOS AHORA TODO EL DATAFRAME DE FORMA QUE SEA APLICABLE A CUALQUIERA DE LOS DATA FRAMES DE LOS CASOS... \n",
    "\n",
    "lista_minimos_col = []\n",
    "lista_maximos_col = []\n",
    "\n",
    "# recorremos las columnas del DATA FRAME\n",
    "for i in range (df.shape[1]): \n",
    "    #print df_sencillo.iloc[1][i:1]\n",
    "    #print df_sencillo.values[1][i]\n",
    "    # añadimos el MIN de esa columna del dataframe\n",
    "    lista_minimos_col.append(df.ix[df[df.columns[i]].idxmin()][df.columns[i]])\n",
    "    lista_maximos_col.append(df.ix[df[df.columns[i]].idxmax()][df.columns[i]])\n",
    "\n",
    "print lista_minimos_col\n",
    "print lista_maximos_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RECORREMOS AHORA TODO EL DATAFRAME DE FORMA QUE SEA APLICABLE A CUALQUIERA DE LOS DATA FRAMES DE LOS CASOS... \n",
    "import pandas \n",
    "df_sencillo = pandas.DataFrame(np.random.randn(5,3),columns=['A','B','C']) \n",
    "print df_sencillo\n",
    "\n",
    "lista_minimos_col = []\n",
    "lista_maximos_col = []\n",
    "\n",
    "print \"============================================\"\n",
    "\n",
    "# recorremos las columnas del DATA FRAME\n",
    "for i in range (df_sencillo.shape[1]): \n",
    "    #print df_sencillo.iloc[1][i:1]\n",
    "    #print df_sencillo.values[1][i]\n",
    "    # añadimos el MIN de esa columna del dataframe\n",
    "    lista_minimos_col.append(df_sencillo.ix[df_sencillo[df_sencillo.columns[i]].idxmin()][df_sencillo.columns[i]])\n",
    "    lista_maximos_col.append(df_sencillo.ix[df_sencillo[df_sencillo.columns[i]].idxmax()][df_sencillo.columns[i]])\n",
    "\n",
    "print lista_minimos_col\n",
    "print lista_maximos_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora calculamos los puntos cercanos a un punto dado para calcular donde están mas proximas los puntos de categoria diferente, (cancerosas). Esto nos ayudará a seleccionar las direcciones más relevantes a la hora de estudiar la evolución del punto en cuestión.\n",
    "##UTLIZAMOS UN EJEMPLO SENCILLO DE DATAFRAME EN SU LUGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Para que funcionen bien los sliders dentro de los valores del Data Set, calculamos los VALORES MAXIMOS Y MINIMOS\n",
    "# DE CADA COLUMNA DEEN EL MISMO\n",
    "import pandas \n",
    "df_sencillo = pandas.DataFrame(np.random.randn(5,3),columns=['A','B','C'])  \n",
    "print df_sencillo\n",
    "\n",
    "print \"esto nos da el indice del MAXIMO valor de la columna\"\n",
    "print df_sencillo.idxmax()\n",
    "print \"y esto el valor en las tres columnas A, B y C  \"\n",
    "registro_max= df_sencillo.ix[df_sencillo['A'].idxmax()]\n",
    "print registro_max\n",
    "print registro_max[0]\n",
    "\n",
    "print \"esto nos da el indice MINIMO\"\n",
    "print df_sencillo.idxmin()\n",
    "print \"y esto el valor en las tres columnas A, B y C  \"\n",
    "registro_min= df_sencillo.ix[df_sencillo['A'].idxmin()]\n",
    "print registro_min\n",
    "print \"\\n \", registro_min[0]\n",
    "\n",
    "print \"============================================\"\n",
    "print \"AHORA generamos un valor random entre los EXTREMOS de cada columna -----\"\n",
    "import random\n",
    "min_A= df_sencillo.ix[df_sencillo['A'].idxmin()]\n",
    "max_A= df_sencillo.ix[df_sencillo['A'].idxmax()]\n",
    "\n",
    "# Como A = df_sencillo.columns[0]   , esto se puede escribir como \n",
    "min_A= df_sencillo.ix[df_sencillo[df_sencillo.columns[0]].idxmin()][df_sencillo.columns[0]]\n",
    "max_A= df_sencillo.ix[df_sencillo[df_sencillo.columns[0]].idxmax()][df_sencillo.columns[0]]\n",
    "print \"el minimo es = \", min_A \n",
    "print \"el maximo es = \", max_A \n",
    "\n",
    "                  \n",
    "muestra_random_emtre_limites = random.uniform(min_A,max_A)\n",
    "print \"============================================\"\n",
    "\n",
    "print \"el numero random entre \", min_A, \" y \", max_A,  \"en la primera coluna es : \", muestra_random_emtre_limites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECORDATORIO DE SELECCION DE CELDAS Y COLUMNAS\n",
    "import pandas \n",
    "df_sencillo = pandas.DataFrame(np.random.randn(2,3),columns=['A','B','C']) \n",
    "print df_sencillo\n",
    "### asi seleccionamos el NOMBRE de la ultima columna\n",
    "print df_sencillo.columns[-1:]\n",
    "### su valor es \n",
    "#print df_sencillo.columns[df_sencillo.columns[-1:]]\n",
    "print df_sencillo.iloc[1][-1:]\n",
    "\n",
    "### valores del dataframe\n",
    "print df_sencillo.values[1][1]\n",
    "\n",
    "### asi obtenemos el numero de columnas. el de filas es df_sencillo.shape[0]\n",
    "#print df_sencillo.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECORREMOS AHORA TODO EL DATAFRAME DE FORMA QUE SEA APLICABLE A CUALQUIERA DE LOS DATA FRAMES DE LOS CASOS... \n",
    "import pandas \n",
    "df_sencillo = pandas.DataFrame(np.random.randn(5,3),columns=['A','B','C']) \n",
    "print df_sencillo\n",
    "\n",
    "lista_minimos_col = []\n",
    "lista_maximos_col = []\n",
    "\n",
    "print \"============================================\"\n",
    "\n",
    "#### recorremos las columnas del DATA FRAME\n",
    "for i in range (df_sencillo.shape[1]): \n",
    "    #print df_sencillo.iloc[1][i:1]\n",
    "    #print df_sencillo.values[1][i]\n",
    "    ####  añadimos el MIN de esa columna del dataframe\n",
    "    lista_minimos_col.append(df_sencillo.ix[df_sencillo[df_sencillo.columns[i]].idxmin()][df_sencillo.columns[i]])\n",
    "    lista_maximos_col.append(df_sencillo.ix[df_sencillo[df_sencillo.columns[i]].idxmax()][df_sencillo.columns[i]])\n",
    "\n",
    "print lista_minimos_col\n",
    "print lista_maximos_col\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICCIONES CON INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vamos a hacer predicciones :\n",
    "\n",
    "example_measures = np.array([[10,5,5,3,6,7,7,10,1]])\n",
    "example_measures = example_measures.reshape(len(example_measures), -1)\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5L 1L 1L ..., 1L 1L 2L]\n",
      " [5L 4L 4L ..., 2L 1L 2L]\n",
      " [3L 1L 1L ..., 1L 1L 2L]\n",
      " ..., \n",
      " [5L 10L 10L ..., 10L 2L 4L]\n",
      " [4L 8L 6L ..., 6L 1L 4L]\n",
      " [4L 8L 8L ..., 4L 1L 4L]]\n"
     ]
    }
   ],
   "source": [
    "print(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2 PARTE: gráficas-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# condiciones que definen nuevos datasets\n",
    "df_tumoral = df[df.Class > 3]\n",
    "df_NO_tumoral = df[df.Class < 3]\n",
    "\n",
    "df_tumoral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# graficas scattered \n",
    "import matplotlib.pyplot as plt\n",
    "#scattercols = ['price','accommodates', 'number_of_reviews', 'reviews_per_month', 'beds', 'availability_30', 'review_scores_rating']\n",
    "scattercols = df.columns\n",
    "axs = pd.scatter_matrix(df[scattercols],\n",
    "                        figsize=(12, 12), c='red')\n",
    "\n",
    "plt.figure(figsize=(1920,1080))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# definimos una funcion distancia de un registro del data se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_NO_tumoral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('ggplot')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = df_tumoral.Clump_Thickness\n",
    "y = df_tumoral.Uniform_Cell_Shape\n",
    "z = df_tumoral.Unifom_Cell_Size\n",
    "\n",
    "x2 = df_NO_tumoral.Clump_Thickness\n",
    "y2 = df_NO_tumoral.Uniform_Cell_Shape\n",
    "z2 = df_NO_tumoral.Unifom_Cell_Size\n",
    "\n",
    "\n",
    "ax1.scatter(x, y, z, c='g', marker='o')\n",
    "ax1.scatter(x2, y2, z2, c ='r', marker='o')\n",
    "\n",
    "ax1.set_xlabel('Espesor')\n",
    "ax1.set_ylabel('Forma Celular')\n",
    "ax1.set_zlabel(u'Tamaño Celular')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imprimimos las 3 primeras variables de prueba\n",
    "\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('ggplot')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "\n",
    "x = df_tumoral.eval(df_tumoral.columns[1])\n",
    "y =  df_tumoral.eval(df_tumoral.columns[2])\n",
    "z =  df_tumoral.eval(df_tumoral.columns[3])\n",
    "\n",
    "x2 = df_NO_tumoral.eval(df_NO_tumoral.columns[1])\n",
    "y2 = df_NO_tumoral.eval(df_NO_tumoral.columns[2])\n",
    "z2 = df_NO_tumoral.eval(df_NO_tumoral.columns[3])\n",
    "\n",
    "\n",
    "ax1.scatter(x, y, z, c='g', marker='o')\n",
    "ax1.scatter(x2, y2, z2, c ='r', marker='o')\n",
    "\n",
    "ax1.set_xlabel('Espesor')\n",
    "ax1.set_ylabel('Forma Celular')\n",
    "ax1.set_zlabel(u'Tamaño Celular')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.columns[9])\n",
    "print(len(df.columns))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# funcion GENERICA QUE DIBUJA UNA COMBINACION particulr de las variable\n",
    "\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "def dibuja_grafica(i,j,k):\n",
    "\n",
    "    style.use('ggplot')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "    x = df_tumoral.eval(df_tumoral.columns[i])\n",
    "    y =  df_tumoral.eval(df_tumoral.columns[j])\n",
    "    z =  df_tumoral.eval(df_tumoral.columns[k])\n",
    "\n",
    "    x2 = df_NO_tumoral.eval(df_NO_tumoral.columns[i])\n",
    "    y2 = df_NO_tumoral.eval(df_NO_tumoral.columns[j])\n",
    "    z2 = df_NO_tumoral.eval(df_NO_tumoral.columns[k])\n",
    "\n",
    "    ax1.scatter(x, y, z, c='g', label='TUMORALES', marker='o')\n",
    "    ax1.scatter(x2, y2, z2, c ='r', label='SANAS', marker='o')\n",
    "    \n",
    "    #plt.scatter(x,y, label='TUMORALES', color='g', s=25, marker=\"o\")\n",
    "    #plt.scatter(x2,y2, label='SANAS', color='r', s=25, marker=\"o\")\n",
    " \n",
    "    ax1.set_xlabel(df_tumoral.columns[i])\n",
    "    ax1.set_ylabel(df_tumoral.columns[j])\n",
    "    ax1.set_zlabel(df_tumoral.columns[k])\n",
    "    \n",
    "    plt.title('Breast Cancer Dataset Analysis               ')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()  \n",
    "    #plt.savefig('graf_'+df_tumoral.columns[i]+df_tumoral.columns[j]+df_tumoral.columns[k]+'.png')\n",
    "\n",
    "dibuja_grafica(1,2,4)\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# representacion de todas las GRAFICAS combinacion total de variables\n",
    "\n",
    "for counter1 in range(0,len(df.columns)-4):\n",
    "    for counter2 in range(counter1 + 1,len(df.columns)):\n",
    "        for counter3 in range(counter2 + 1,len(df.columns)):\n",
    "            try:\n",
    "                dibuja_grafica(counter1,counter2,counter3)\n",
    "                #print counter1,\",\", counter2,\",\", counter3\n",
    "            except Exception:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recordatorio de graficas en 2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [1,2,3,4,5,6,7,8]\n",
    "y = [5,2,4,2,1,4,5,2]\n",
    "\n",
    "x2 = [2,3,3,7,5,2,5]\n",
    "y2 = [3,1,0,2,4,5,2]\n",
    "\n",
    "\n",
    "#style.use('ggplot')\n",
    "\n",
    "fig = plt.figure() \n",
    "\n",
    "# AÑADIMOS UN SUBPLOT sobre fig\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(x, y, c='g', marker='o')\n",
    "ax1.scatter(x2, y2, c ='r', marker='o')\n",
    "\n",
    "plt.scatter(x,y, label='TUMORALES', color='g', s=25, marker=\"o\")\n",
    "plt.scatter(x2,y2, label='NORMALES', color='r', s=25, marker=\"o\")\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Breast Cancer Analysis')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GRAFICA EN 2D  con la clase como Z\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "def dibuja_grafica2D(i,j,k):\n",
    "\n",
    "    style.use('ggplot')\n",
    "    \n",
    "    x = df_tumoral.eval(df_tumoral.columns[i])\n",
    "    y =  df_tumoral.eval(df_tumoral.columns[j])\n",
    "\n",
    "    x2 = df_NO_tumoral.eval(df_NO_tumoral.columns[i])\n",
    "    y2 = df_NO_tumoral.eval(df_NO_tumoral.columns[j])\n",
    "    \n",
    "    fig = plt.figure() \n",
    "\n",
    "    # AÑADIMOS UN SUBPLOT sobre fig\n",
    "    ax1 = fig.add_subplot(111)\n",
    "\n",
    "    ax1.scatter(x, y, c='g', marker='o')\n",
    "    ax1.scatter(x2, y2, c ='r', marker='o')\n",
    "\n",
    "    plt.scatter(x,y, label='TUMORALES', color='g', s=25, marker=\"o\")\n",
    "    plt.scatter(x2,y2, label='SANAS', color='r', s=25, marker=\"o\")\n",
    "\n",
    "    # ax1.scatter(x, y, z, c='g', marker='o')\n",
    "    # ax1.scatter(x2, y2, z2, c ='r', marker='o')\n",
    "\n",
    "    ax1.set_xlabel(df_tumoral.columns[i])\n",
    "    ax1.set_ylabel(df_tumoral.columns[j])\n",
    "\n",
    "\n",
    "    plt.title('Breast Cancer Dataset Analysis - Human Forecast')\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "    plt.savefig('graficos/graf_'+df_tumoral.columns[i]+df_tumoral.columns[j]+'.png')\n",
    "\n",
    "\n",
    "dibuja_grafica2D(1,2,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pero ahora solo estamos interesados en combinar dos a dos \n",
    "# con z que sea la clase de tumor que es el indice 9\n",
    "\n",
    "for counter1 in range(0,len(df.columns)-2):\n",
    "    for counter2 in range(counter1 + 1,len(df.columns)-1):\n",
    "            try:\n",
    "                dibuja_grafica2D(counter1,counter2,9)\n",
    "                #print counter1,\",\", counter2\n",
    "            except Exception:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
